=======[‚ùå TEORIA ]=================================================================================
Fundamento t√©cnico vCPU:

- El overcommit de CPU es posible porque Proxmox/KVM permite asignar m√°s vCPUs que cores f√≠sicos.
- Linux KVM/QEMU y el scheduler del host manejan la distribuci√≥n del tiempo de CPU entre las VMs, gestionando el acceso concurrente.

Fundamento t√©cnico Cluster:

- En Proxmox VE (que utiliza Corosync como capa de clustering), el ‚Äúquorum‚Äù es el mecanismo que asegura que s√≥lo un subconjunto mayoritario de nodos pueda tomar decisiones v√°lidas sobre el estado del cl√∫ster y sus recursos. 

=======[‚ùå CREAR M√ÅQUINA VIRTUAL ]==================================================================
# buena pr√°ctica para mejor visualizaci√≥n
‚öôÔ∏è > Sort Key: Name

# creo una nueva m√°quina virtual
sobre el Node indicado > Create VM

# para crear una m√°quina virtual o contenedor es recomendable hacerlo desde:
local-lvm


# Ajustes al crear la m√°quina:
Create VM
------------------------------------------------------------------------------
+ General:
*********************************************************
Name: ~
_
+ OS:
*********************************************************
Storage: Synology (para producci√≥n) | local (para pruebas o desarrollo)
OS: (selecciono la √∫ltima versi√≥n de cada S.O)
_
+ System:
*********************************************************
_
+ Disk:
*********************************************************
Bus/Devicec: SATA | 0
Storage: Synology (para producci√≥n) | local (para pruebas o desarrollo)
Disk Size: 40 GiB (o los necesarios)
Cache: Write Back
[x] Avanced
~
[x] SSD emulation
_
+ CPU:
*********************************************************
# es recomendable poner un socket y varios cores
Sockets: 1 
Cores: 4
_
+ Memory:
*********************************************************
Memory (MiB): 2048 (o los que sean necesarios, en este caso 2GB | 4096 = 4GB) 
_
+ Network:
*********************************************************
Bridge: vmbr0
VLAN Tag: (el tag de vlan correspondiente no la vlan de red)
Model: 
------------------------------------------------------------------------------





===============================================================================
                                ASIGNACI√ìN DE CPU EN PROXMOX
===============================================================================
# Cores asignados en Proxmox: vCPUs que configuras para cada VM
-------------------------------------------------------------------------------

-------------------------------------------------------------------------------

M√©todo             | ¬øCPU f√≠sica directa?         | Descripci√≥n t√©cnica
-------------------|------------------------------|-------------------------------------------------------------
Asignar vCPU       | ‚ùå No                       | Lo m√°s com√∫n. El hipervisor distribuye el uso entre vCPUs.
CPU pinning        | ‚úÖ Parcialmente             | Asocia vCPUs a cores f√≠sicos espec√≠ficos. Ejemplos: taskset, numactl, configuraci√≥n en XML/QEMU args.
CPU passthrough    | ‚úÖ S√≠, pero para PCI        | Passthrough para hardware PCI (GPU, etc.). No aplica para CPU.


-------------------------------------------------------------------------------
Recomendaci√≥n para un host con 4 cores f√≠sicos:
+---------------------------------+---------------------------------+
| Tipo de uso                     | N¬∫ de VMs seguras (1 vCPU c/u)  |
+---------------------------------+---------------------------------+
| Carga baja (CLI, routers, logs) | 8 ‚Äì 10                          |
| Carga mixta                     | 5 ‚Äì 6                           |
| Carga alta (pentesting, GVM)    | 2 ‚Äì 3 m√°ximo simult√°neas        |
+---------------------------------+---------------------------------+

-------------------------------------------------------------------------------
¬øC√≥mo se ejecutan m√°s vCPUs que cores f√≠sicos?

- Cada vCPU es una porci√≥n de tiempo (time slice) de un core f√≠sico.
- El scheduler del hipervisor intercala tareas en milisegundos.
- Si varias VMs no usan CPU intensivamente al mismo tiempo, funciona sin problemas.
- Si todas realizan carga pesada simult√°neamente, se genera cola y latencia.

-------------------------------------------------------------------------------
Resumen clave:

‚úÖ Puedes asignar tantas vCPUs como quieras.  
‚ö†Ô∏è Est√°s repartiendo tiempo de CPU, no creando potencia adicional real.  
üß† Usa overcommit con prudencia: eval√∫a la carga, no solo el n√∫mero de vCPUs.

-------------------------------------------------------------------------------
Consejos t√©cnicos:

- Usa drivers **virtio** para disco y red, mejora rendimiento y compatibilidad.
- Habilita **ballooning** para RAM en laboratorios para mejor gesti√≥n din√°mica.
- Para menos overhead, considera usar contenedores (LXC) en vez de VMs.
- Aplica **CPU limits y CPU shares** para controlar recursos si varias VMs se activan a la vez.

-------------------------------------------------------------------------------
Fundamento t√©cnico:

- El overcommit de CPU es posible porque Proxmox/KVM permite asignar m√°s vCPUs que cores f√≠sicos.
- Linux KVM/QEMU y el scheduler del host manejan la distribuci√≥n del tiempo de CPU entre las VMs, gestionando el acceso concurrente.

===============================================================================
